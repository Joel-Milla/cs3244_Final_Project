{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6386e32-e130-4621-bc91-e98390e8e5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, root_mean_squared_error, median_absolute_error\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LassoCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Deep Learning\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcff536-ea94-4413-ae20-e29bae3a55b0",
   "metadata": {},
   "source": [
    "#### Functions for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f74ed174-4b39-4b6a-8d6b-9ab394c68312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, X_test_, y_test_, y_pred=None):\n",
    "    '''\n",
    "    We test our model and print various metrics for comparison\n",
    "\n",
    "    Params:\n",
    "    model: to test\n",
    "    X_test: which are features to test\n",
    "    y_test: the real values that match X_test\n",
    "    '''\n",
    "    if y_pred is None:\n",
    "        y_pred = model.predict(X_test_)\n",
    "    \n",
    "    rmse = root_mean_squared_error(y_test_, y_pred)\n",
    "    mae = mean_absolute_error(y_test_, y_pred)\n",
    "    mse = mean_squared_error(y_test_, y_pred)\n",
    "    mabse = median_absolute_error(y_test_, y_pred)\n",
    "\n",
    "    print(f\"Root mean Squared Error: {rmse:.4f}\")\n",
    "    print(f\"Mean absolute Error: {mae:.4f}\")\n",
    "    print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "    print(f\"Median absolute Error: {mabse:.4f}\")\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "def visualize(y_test, y_pred):\n",
    "    '''\n",
    "    Params:\n",
    "    y_test: the real values that match X_test\n",
    "    y_pred: the models predicted y values\n",
    "    '''\n",
    "    plt.scatter(y_test, y_pred, alpha=0.3)  # alpha=0.3 for semi-transparent dots\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)  # red diagonal line\n",
    "    plt.xlabel(\"Actual Comment Volume\")\n",
    "    plt.ylabel(\"Predicted Comment Volume\")\n",
    "    plt.title(\"Actual vs Predicted Comment Volume\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed791726-fcbf-49b2-ab73-cb6fe5a4d718",
   "metadata": {},
   "source": [
    "## Experiements\n",
    "In the following code sections, each \"option\" represents an experiment we conducted to evaluate different model improvements. Through these experiments, we implemented various techniques to enhance model performance and gain insights through our chosen evaluation metrics.\n",
    "#### Option 1: Train and test without any data preprocessing or feature engineering\n",
    "Consists of training and testing models without any preprocessing or feature engineering. This creates our baseline models that serve as reference points for comparison as we apply techniques in subsequent experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd9c15a5-e4f8-4974-928a-8dfe26d56b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40949, 54)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['Page Popularity/likes', 'Page Checkins', 'Page talking about', 'Page Category', 'Derived Feature 5', 'Derived Feature 6', 'Derived Feature 7', \n",
    "    'Derived Feature 8', 'Derived Feature 9', 'Derived Feature 10', 'Derived Feature 11', 'Derived Feature 12', 'Derived Feature 13', \n",
    "    'Derived Feature 14', 'Derived Feature 15', 'Derived Feature 16', 'Derived Feature 17', 'Derived Feature 18', 'Derived Feature 19', 'Derived Feature 20', \n",
    "    'Derived Feature 21', 'Derived Feature 22', 'Derived Feature 23', 'Derived Feature 24', 'Derived Feature 25', 'Derived Feature 26', 'Derived Feature 27', \n",
    "    'Derived Feature 28', 'Derived Feature 29', 'CC1', 'CC2', 'CC3', 'CC4', 'CC5', 'Base time', 'Post length', 'Post Share Count', 'Post Promotion Status',\n",
    "    'H Local', 'Post Published Sunday', 'Post Published Monday', 'Post Published Tuesday',  'Post Published Wednesday', 'Post Published Thursday', \n",
    "    'Post Published Friday', 'Post Published Saturday', 'Base DateTime Sunday', 'Base DateTime Monday', 'Base DateTime Tuesday','Base DateTime Wednesday', \n",
    "    'Base DateTime Thursday', 'Base DateTime Friday', 'Base DateTime Saturday', 'Target Variable' ]\n",
    "\n",
    "base_training_complete = pd.read_csv('./Dataset/Training/Features_Variant_1.csv', sep=',', header=None, names=columns)\n",
    "base_training_complete.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "167ba805-5a61-41f8-a13b-f02a524a776c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The .values changes type from pandas to a numpy array, it strips the labels of rows and columns\n",
    "'''\n",
    "base_X = base_training_complete.iloc[:, :-1]\n",
    "base_y = base_training_complete.iloc[:, -1]\n",
    "\n",
    "base_X_np = base_training_complete.iloc[:, :-1].values # Independent variables - the features.\n",
    "base_y_np = base_training_complete.iloc[:, -1].values # dependent variable - prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3355395-e446-48ee-9d41-41669187313d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_X_train, base_X_test, base_y_train, base_y_test = train_test_split(base_X_np, base_y_np, test_size = 0.3, random_state = 1) # 30% for testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bddb51a2-77de-4215-a47f-5d590cd58c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_lin_regression = LinearRegression()\n",
    "base_lin_regression.fit(base_X_train, base_y_train)  # lec 4, slide 46 - uses normal equations since we have a small/medium-sized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d4ebcae-7f94-4bc7-b89a-a18f71c3577e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'calculate_smape' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m base_y_pred \u001b[38;5;241m=\u001b[39m test(base_lin_regression, base_X_test, base_y_test)\n",
      "Cell \u001b[0;32mIn[3], line 18\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(model, X_test_, y_test_, y_pred)\u001b[0m\n\u001b[1;32m     16\u001b[0m mabse \u001b[38;5;241m=\u001b[39m median_absolute_error(y_test_, y_pred)\n\u001b[1;32m     17\u001b[0m r2 \u001b[38;5;241m=\u001b[39m r2_score(y_test_, y_pred)\n\u001b[0;32m---> 18\u001b[0m smape \u001b[38;5;241m=\u001b[39m calculate_smape(y_test_, y_pred)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRoot mean Squared Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrmse\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean absolute Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmae\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'calculate_smape' is not defined"
     ]
    }
   ],
   "source": [
    "base_y_pred = test(base_lin_regression, base_X_test, base_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38d324e-4d9b-4f67-a419-ae7d09ac46d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(base_y_test, base_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dc5319-264a-47fd-80ff-35063f7d09f9",
   "metadata": {},
   "source": [
    "#### Option 2: Apply basic preprocessing: drop duplicates, drop column that has only zeros\n",
    "Applies basic preprocessing steps to clean our dataset by removing duplicates and dropping columns that provide no information value. This experiment helps us understand how even simple data cleaning can affect model performance before we implement more complex feature engineering techniques. Although, we don't expect to see big improvements compared from baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f811d46-0a68-40be-afb9-76e4bc4724da",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_training_complete = pd.read_csv('./Dataset/Training/Features_Variant_1.csv', sep=',', header=None, names=columns)\n",
    "preprocess_training_complete.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dc7fcc-8b17-4d02-b7c0-e2807fae727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_training_complete = preprocess_training_complete.drop(\"Post Promotion Status\", axis='columns') # Drop column that has only zeros\n",
    "preprocess_training_complete = preprocess_training_complete.drop_duplicates() # drop duplicates in our dataset\n",
    "\n",
    "'''\n",
    "The .values changes type from pandas to a numpy array, it strips the labels of rows and columns\n",
    "'''\n",
    "preprocess_X = preprocess_training_complete.iloc[:, :-1]\n",
    "preprocess_y = preprocess_training_complete.iloc[:, -1]\n",
    "\n",
    "preprocess_X_np = preprocess_training_complete.iloc[:, :-1].values # Independent variables - the features.\n",
    "preprocess_y_np = preprocess_training_complete.iloc[:, -1].values # dependent variable - prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8e694c-bac3-44d6-92f9-7ece1b4b7dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_X_train, preprocess_X_test, preprocess_y_train, preprocess_y_test = train_test_split(preprocess_X_np, preprocess_y_np, test_size = 0.3, random_state = 1) # 30% for testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999a88f5-16e3-4b37-b497-8d2cdeec3430",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_lin_regression = LinearRegression()\n",
    "preprocess_lin_regression.fit(preprocess_X_train, preprocess_y_train)  # lec 4, slide 46 - uses normal equations since we have a small/medium-sized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c50230-9375-4629-ba89-a70972fb5004",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_y_pred = test(preprocess_lin_regression, preprocess_X_test, preprocess_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47adaded-ec18-4ee5-85e7-7ad98873fb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(preprocess_y_test, preprocess_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c25697d-85df-40ab-a47e-48e89d99c8bd",
   "metadata": {},
   "source": [
    "#### Option 3: Apply data preprocessing and feature engineering from WithoutMethods.ipynb\n",
    "Option 3 extends our approach by implementing more comprehensive data preprocessing and feature engineering techniques developed in the 2_DataPreprocessing.ipynb notebook. In this experiment, we standardize our numerical features to ensure all values are on the same scale, which can significantly improve linear models' performance since they're sensitive to feature magnitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d85f8c-0d3a-42a3-84ef-671a6932cb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_data = pd.read_csv('Preprocessed_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead808d3-33ad-4ca3-8009-676a1f028468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate features and target\n",
    "features_X = features_data.drop(columns=[\"Target_Comment_Volume\"])\n",
    "features_y = features_data[\"Target_Comment_Volume\"]\n",
    "\n",
    "# scale features\n",
    "scaler = StandardScaler()\n",
    "features_X_scaled = scaler.fit_transform(features_X)  # scale before splitting train-test so that all values are in the same range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fe4c6c-67de-45b8-a4aa-8d907fe9e1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_X_train, features_X_test, features_y_train, features_y_test = train_test_split(features_X_scaled, features_y, test_size=0.3, random_state=1)  # setting random_state allows for the same split on each runX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=1)  # setting random_state allows for the same split on each run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e4bde6-df8e-40e1-a2f7-991e5e242a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_lin_regression = LinearRegression()\n",
    "features_lin_regression.fit(features_X_train, features_y_train)  # lec 4, slide 46 - uses normal equations since we have a small/medium-sized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2bcec8-06d1-4cf2-97a9-d52817d20181",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_y_pred = test(features_lin_regression, features_X_test, features_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1ac461-a0e3-4227-8eb7-8b92db6410c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(features_y_test, features_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8cc690-7818-4d82-b116-8654694403d0",
   "metadata": {},
   "source": [
    "#### Option 4: Apply L2 (ridge) regularization\n",
    "Option 4 introduces L2 (ridge) regularization to our linear model, which could help prevent overfitting by adding a penalty on the magnitude of coefficients. This technique could be particularly useful for our Facebook comment prediction dataset because many features show multicollinearity, and regularization can stabilize predictions when working with potentially redundant variables and outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1b1a82-bf7e-41e0-bf95-7f2d25bc1d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_data = pd.read_csv('Preprocessed_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859db6e3-8658-4b4e-bf84-a3f8e0024d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate features and target\n",
    "l2_X = l2_data.drop(columns=[\"Target_Comment_Volume\"])\n",
    "l2_y = l2_data[\"Target_Comment_Volume\"]\n",
    "\n",
    "# scale features\n",
    "scaler = StandardScaler()\n",
    "l2_X_scaled = scaler.fit_transform(l2_X)  # scale before splitting train-test so that all values are in the same range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3ea6fa-5250-44d8-906a-e34cea6e4081",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_X_train, l2_X_test, l2_y_train, l2_y_test = train_test_split(l2_X_scaled, l2_y, test_size=0.3, random_state=1)  # setting random_state allows for the same split on each runX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=1)  # setting random_state allows for the same split on each run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7210aec8-1d39-4bce-bbcc-a656c71cd7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = Ridge()\n",
    "l2.fit(l2_X_train, l2_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7670a8-3724-40de-9e67-3c0f158967a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_y_pred = test(l2, l2_X_test, l2_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402e6b28-e53f-410c-a75d-66c1744de3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(l2_y_test, l2_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794d8140-6123-4dfb-9fc2-5b54f4f402df",
   "metadata": {},
   "source": [
    "#### Option 5: Apply PCA with cross-validation on Linear regression and L2 regularization\n",
    "Option 5 introduces Principal Component Analysis (PCA) combined with cross-validation to further improve our linear models. PCA helps address multicollinearity by transforming our features into uncorrelated components while retaining 95% of the variance. We implement this approach to combine dimensionality reduction with ridge regression in a robust way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d8fc5d-e342-4b8e-8b7b-a25b721be5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_data = pd.read_csv('Preprocessed_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4832ee95-29dc-4310-961c-d1b16fa32140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate features and target\n",
    "pca_X = pca_data.drop(columns=[\"Target_Comment_Volume\"])\n",
    "pca_y = pca_data[\"Target_Comment_Volume\"]\n",
    "\n",
    "# scale features\n",
    "scaler = StandardScaler()\n",
    "pca_X_scaled = scaler.fit_transform(pca_X)  # scale before splitting train-test so that all values are in the same range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3dc0e3-868f-4505-a5f2-fce09800e013",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train_flag = \"Ridge\" # either LinReg or Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbdf2e0-8f36-4d4b-9747-4b462f8888f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "pca = PCA(n_components=0.95)  # retain 95% variances\n",
    "\n",
    "if model_train_flag == \"LinReg\":\n",
    "    pipeline = Pipeline([\n",
    "        ('pca', pca),\n",
    "        ('reg', LinearRegression())\n",
    "    ])\n",
    "elif model_train_flag == \"Ridge\":\n",
    "    pipeline = Pipeline([\n",
    "        ('pca', pca),\n",
    "        ('reg', Ridge(alpha=10))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d6518a-eb63-4491-8c9f-2bb847cc08d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_X_train, pca_X_test, pca_y_train, pca_y_test = train_test_split(pca_X_scaled, pca_y, test_size=0.3, random_state=1)  # setting random_state allows for the same split on each runX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=1)  # setting random_state allows for the same split on each run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abebcb95-d3af-4e59-8308-79b7f7540bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit pipeline\n",
    "pipeline.fit(pca_X_train, pca_y_train)\n",
    "pca_y_pred = pipeline.predict(pca_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ee6837-e5b3-44f0-b3f0-2cec075af90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "print(f\"{model_train_flag} Regression with PCA Results\")\n",
    "print(f\"Train R²: {pipeline.score(pca_X_train, pca_y_train):.4f}\")\n",
    "print(f\"Test R²: {pipeline.score(pca_X_test, pca_y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d170e020-1311-453e-83d8-c26d4928e44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(pipeline, pca_X_scaled, pca_y, scoring='r2', cv=cv)\n",
    "print(\"Cross-Validation R² scores:\", cv_scores)\n",
    "print(\"Average R²:\", np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f35541-1101-481a-a0cd-64c551fa2d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(pipeline, pca_X_test, pca_y_test, pca_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45352c0-f685-4dce-b013-710a47955c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(pca_y_test, pca_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b515e895-1e49-4f79-8572-20bf65aa5695",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "LinReg Regression with PCA Results\n",
    "\n",
    "Train R²: 0.3032\n",
    "\n",
    "Test R²: 0.3277\n",
    "\n",
    "Cross-Validation R² scores: [0.35808581 0.35334128 0.23436523 0.33982897 0.26431706]\n",
    "\n",
    "Average R²: 0.3099876699387849\n",
    "\n",
    "Root mean Squared Error: 26.5305\n",
    "\n",
    "Mean absolute Error: 8.7832\n",
    "\n",
    "Mean Squared Error: 703.87\n",
    "\n",
    "Median absolute Error: 4.8714\n",
    "\n",
    "Ridge Regression with PCA Results\n",
    "\n",
    "Train R²: 0.3032\n",
    "\n",
    "Test R²: 0.3277\n",
    "\n",
    "Cross-Validation R² scores: [0.35809013 0.35334543 0.23437372 0.33981973 0.26431705]\n",
    "\n",
    "Average R²: 0.309989212860658\n",
    "\n",
    "Root mean Squared Error: 26.5305\n",
    "\n",
    "Mean absolute Error: 8.7823\n",
    "\n",
    "Mean Squared Error: 703.87\n",
    "\n",
    "Median absolute Error: 4.8691\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860c7d71-f52e-4e1c-b24f-dcb10e7e721f",
   "metadata": {},
   "source": [
    "#### Option 6: Apply autoencoder from DataPreprocessing.ipynb\n",
    "Option 6 implements an autoencoder neural network for dimensionality reduction, which offers advantages over PCA by capturing non-linear relationships between features. This technique creates a compressed representation of our input data in a 32-dimensional latent space, potentially revealing complex patterns that linear methods might miss when predicting Facebook comment volumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5b3168-af7f-4917-9af4-5a1ff22e07f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_data = pd.read_csv('Preprocessed_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cd9928-8037-4724-ab20-a9cc4a138921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate features and target\n",
    "auto_X = auto_data.drop(columns=[\"Target_Comment_Volume\"])\n",
    "auto_y = auto_data[\"Target_Comment_Volume\"]\n",
    "\n",
    "# scale features\n",
    "scaler = StandardScaler()\n",
    "auto_X_scaled = scaler.fit_transform(auto_X)  # scale before splitting train-test so that all values are in the same range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ab4def-609f-4f10-8aaa-5ca189d79cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = auto_X_scaled.shape[1]\n",
    "encoding_dim = 32 # Dimension of the encoded representation\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoded = Dense(128, activation='relu')(input_layer)\n",
    "encoded = Dense(encoding_dim, activation='relu')(encoded)\n",
    "decoded = Dense(128, activation='relu')(encoded)\n",
    "decoded = Dense(input_dim, activation='linear')(decoded)\n",
    "\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "encoder = Model(input_layer, encoded)\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "autoencoder.fit(auto_X_scaled, auto_X_scaled, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "# Encode features\n",
    "X_encoded = encoder.predict(auto_X_scaled)\n",
    "X_train_enc, X_test_enc, y_train_enc, y_test_enc = train_test_split(X_encoded, auto_y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6c9f39-aa50-4e5e-8636-e6647c3ebebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "auto_lr = LinearRegression()\n",
    "auto_lr.fit(X_train_enc, y_train_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5af182-30f1-4f69-9310-bcae4d06be12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"<----Linear Regression after autoencoder---->\")\n",
    "y_pred_enc = test(auto_lr, X_test_enc, y_test_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b863049-0862-44cc-a44c-3c8faa1b10db",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(y_test_enc, y_pred_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e281935f-ae83-4300-840f-0e299008c276",
   "metadata": {},
   "source": [
    "#### Option 7: Feature Engineering\n",
    "Option 7 implements the feature engineered data from 3_FeatureEngineering.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71d4a91-042c-4b6a-9bd5-a1e4e57ac373",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train_df.csv\")\n",
    "test_df = pd.read_csv(\"test_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30899d6f-45fa-416b-a0f3-19748d74818d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Split into features (X) and target (y)\n",
    "X_train      = train_df.drop(columns='Target_Comment_Volume')\n",
    "y_train      = train_df['Target_Comment_Volume']\n",
    "\n",
    "X_test       = test_df.drop(columns='Target_Comment_Volume')\n",
    "y_test       = test_df['Target_Comment_Volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78a72ce-29a6-4da0-8114-ee6000d479ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression on original features\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97548f5-3f53-4383-8daa-cf2954d4db2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = test(lr, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e97718-5bf0-4201-add8-f80abf9cbbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(y_test, y_pred_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c33075-04c6-45f0-a466-58fa3e790d80",
   "metadata": {},
   "source": [
    "## Other Experiments\n",
    "#### 1. Removing of outliers\n",
    "results of test: (Train R² / Test R² / MSE / RMSE)\n",
    "\n",
    "a) no outlier removal: model fits well, but affected by large outliers (0.56, 0.53, 467.04, 21.61)\n",
    "\n",
    "b) remove x and y outliers: low error, but model trained on less data (0.32, 0.34, 1.72, 1.31) \n",
    "\n",
    "c) clip only the target value: balanced — outliers controlled, full dataset used (0.49, 0.48, 3.91, 1.98)\n",
    "##### Conclusion: Clipping only the target value when removing outliers performed the best but not as well as other methods, removed to be able to compare metrics between models \n",
    "\n",
    "#### 2. Log transform target value\n",
    "##### Conclusion: This resulted in very poor results and a negative r^2 value and so we opted to not log tranform the y-values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74128aa-00da-4246-bfe7-1704122fac4a",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "- Performed the best with feature engineering as it removed irrelevant/misleading features\n",
    "- Underfitted on complex or high-comment posts\n",
    "- Highlights the need for non-linear or ensemble models for better accuracy and expressiveness\n",
    "\n",
    "## Future Improvements\n",
    "- polynomial regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
