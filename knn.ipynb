{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18731f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score, mean_absolute_error, median_absolute_error, mean_squared_error\n",
    "\n",
    "# Regression Models\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# Deep Learning\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74807e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('optional_features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28272db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, X_test, y_test, y_pred=None):\n",
    "    '''\n",
    "    We test our model and print various metrics for comparison\n",
    "\n",
    "    Params:\n",
    "    model: to test\n",
    "    X_test: which are features to test\n",
    "    y_test: the real values that match X_test\n",
    "    '''\n",
    "    if y_pred is None:\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "    rmse = root_mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mabse = median_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"Root mean Squared Error: {rmse:.4f}\")\n",
    "    print(f\"Mean absolute Error: {mae:.4f}\")\n",
    "    print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "    print(f\"Median absolute Error: {mabse:.4f}\")\n",
    "    print(f\"R² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783b84a5",
   "metadata": {},
   "source": [
    "In Data Preproccesing step, we found that Auto Encoder is useful for KNN model. Thus, we decided to use Auto Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c7c883f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4354/4354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 159us/step\n",
      "\u001b[1m1866/1866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157us/step\n"
     ]
    }
   ],
   "source": [
    "# 1. Separate features and target\n",
    "X = data.drop(columns=[\"Target_Comment_Volume\"])\n",
    "y = data[\"Target_Comment_Volume\"]\n",
    "\n",
    "# 2. Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 3. Split data BEFORE fitting the autoencoder\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# 4. Define autoencoder architecture\n",
    "input_dim = X_train_scaled.shape[1]\n",
    "encoding_dim = 32  # Dimension of the encoded representation\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoded = Dense(64, activation='relu')(input_layer)\n",
    "encoded = Dense(encoding_dim, activation='relu')(encoded)\n",
    "decoded = Dense(64, activation='relu')(encoded)\n",
    "decoded = Dense(input_dim, activation='linear')(decoded)\n",
    "\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "encoder = Model(input_layer, encoded)\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# 5. Train the autoencoder ONLY on the training set\n",
    "autoencoder.fit(X_train_scaled, X_train_scaled, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "# 6. Encode features using the trained encoder\n",
    "X_train_enc = encoder.predict(X_train_scaled)\n",
    "X_test_enc = encoder.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e0cebf",
   "metadata": {},
   "source": [
    "We aim to evaluate how different K-Nearest Neighbors (KNN) configurations affect regression performance.\n",
    "Specifically, we will experiment with:\n",
    "\n",
    "- Different values for n_neighbors\n",
    "- Different distance metrics such as 'euclidean', 'manhattan', and 'minkowski'\n",
    "This helps identify which combination gives the best predictive results for this dataset.\n",
    "\n",
    "**Why we Used These Parameters**\n",
    "\n",
    "- n_neighbors determines how many neighbors the model considers when making predictions. Testing small and larger values helps balance between bias and variance.\n",
    "- Distance metrics define how similarity between points is measured. Some metrics work better with high-dimensional data or specific feature distributions.\n",
    "\n",
    "**Configurations we Tested**\n",
    "\n",
    "- n_neighbors: 3, 5, 10, and √(n_samples)\n",
    "- metric: 'euclidean', 'manhattan'\n",
    "- weights: 'uniform', 'distance'\n",
    "\n",
    "We kept all other parameters constant while changing one at a time to isolate its effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e541214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean Squared Error: 8.0753\n",
      "Mean absolute Error: 2.2208\n",
      "Mean Squared Error: 65.21\n",
      "Median absolute Error: 0.3333\n",
      "R² Score: 0.9364\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(\n",
    "    n_neighbors=3,\n",
    "    metric='euclidean'\n",
    ")\n",
    "\n",
    "knn.fit(X_train_enc, y_train)\n",
    "test(knn, X_test_enc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75a91df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean Squared Error: 8.3438\n",
      "Mean absolute Error: 2.2654\n",
      "Mean Squared Error: 69.62\n",
      "Median absolute Error: 0.4000\n",
      "R² Score: 0.9322\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(\n",
    "    n_neighbors=5,\n",
    "    metric='euclidean'\n",
    ")\n",
    "\n",
    "knn.fit(X_train_enc, y_train)\n",
    "test(knn, X_test_enc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbd7543d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean Squared Error: 8.4748\n",
      "Mean absolute Error: 2.3890\n",
      "Mean Squared Error: 71.82\n",
      "Median absolute Error: 0.5000\n",
      "R² Score: 0.9300\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(\n",
    "    n_neighbors=10,\n",
    "    metric='euclidean'\n",
    ")\n",
    "\n",
    "knn.fit(X_train_enc, y_train)\n",
    "test(knn, X_test_enc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c4c10ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean Squared Error: 16.0981\n",
      "Mean absolute Error: 3.8089\n",
      "Mean Squared Error: 259.15\n",
      "Median absolute Error: 0.6863\n",
      "R² Score: 0.7474\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(\n",
    "    n_neighbors=int(np.sqrt(len(X_train_enc))),\n",
    "    metric='euclidean'\n",
    ")\n",
    "\n",
    "knn.fit(X_train_enc, y_train)\n",
    "test(knn, X_test_enc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51be1b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean Squared Error: 8.1775\n",
      "Mean absolute Error: 2.2512\n",
      "Mean Squared Error: 66.87\n",
      "Median absolute Error: 0.3333\n",
      "R² Score: 0.9348\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(\n",
    "    n_neighbors=3,\n",
    "    metric='manhattan'\n",
    ")\n",
    "\n",
    "knn.fit(X_train_enc, y_train)\n",
    "test(knn, X_test_enc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "412ababf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean Squared Error: 8.4717\n",
      "Mean absolute Error: 2.3237\n",
      "Mean Squared Error: 71.77\n",
      "Median absolute Error: 0.4000\n",
      "R² Score: 0.9301\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(\n",
    "    n_neighbors=5,\n",
    "    metric='manhattan'\n",
    ")\n",
    "\n",
    "knn.fit(X_train_enc, y_train)\n",
    "test(knn, X_test_enc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e413b7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean Squared Error: 8.9305\n",
      "Mean absolute Error: 2.4694\n",
      "Mean Squared Error: 79.75\n",
      "Median absolute Error: 0.5000\n",
      "R² Score: 0.9223\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(\n",
    "    n_neighbors=10,\n",
    "    metric='manhattan'\n",
    ")\n",
    "\n",
    "knn.fit(X_train_enc, y_train)\n",
    "test(knn, X_test_enc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86ca2ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean Squared Error: 16.9582\n",
      "Mean absolute Error: 3.9056\n",
      "Mean Squared Error: 287.58\n",
      "Median absolute Error: 0.6649\n",
      "R² Score: 0.7197\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(\n",
    "    n_neighbors=int(np.sqrt(len(X_train_enc))),\n",
    "    metric='manhattan'\n",
    ")\n",
    "\n",
    "knn.fit(X_train_enc, y_train)\n",
    "test(knn, X_test_enc, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa20bd0",
   "metadata": {},
   "source": [
    "BEST MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a5c5f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean Squared Error: 7.8324\n",
      "Mean absolute Error: 2.0931\n",
      "Mean Squared Error: 61.35\n",
      "Median absolute Error: 0.4038\n",
      "R² Score: 0.9402\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(\n",
    "    n_neighbors=5,\n",
    "    metric='manhattan',\n",
    "    weights='distance'\n",
    ")\n",
    "\n",
    "knn.fit(X_train_enc, y_train)\n",
    "test(knn, X_test_enc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5e5226d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean Squared Error: 7.6167\n",
      "Mean absolute Error: 2.0361\n",
      "Mean Squared Error: 58.01\n",
      "Median absolute Error: 0.3674\n",
      "R² Score: 0.9435\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(\n",
    "    n_neighbors=3,\n",
    "    metric='euclidean',\n",
    "    weights='distance'\n",
    ")\n",
    "\n",
    "knn.fit(X_train_enc, y_train)\n",
    "test(knn, X_test_enc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e0a8374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean Squared Error: 7.6674\n",
      "Mean absolute Error: 2.0445\n",
      "Mean Squared Error: 58.79\n",
      "Median absolute Error: 0.4121\n",
      "R² Score: 0.9427\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(\n",
    "    n_neighbors=5,\n",
    "    metric='euclidean',\n",
    "    weights='distance'\n",
    ")\n",
    "\n",
    "knn.fit(X_train_enc, y_train)\n",
    "test(knn, X_test_enc, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd00106",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "The best KNN model uses:\n",
    "\n",
    "- 3 or 5 nearest neighbors\n",
    "- Distance-based weighting\n",
    "\n",
    "This configuration outperformed other combinations by giving more influence to closer neighbors, which helped the model better capture local variations in the data. As a result, it produced the most accurate predictions in our evaluation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
